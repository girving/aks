# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Lean 4 formalization of the Ajtai‚ÄìKoml√≥s‚ÄìSzemer√©di (1983) O(n log n) sorting network construction. The project formalizes the proof architecture using the zig-zag product (Reingold‚ÄìVadhan‚ÄìWigderson 2002) as the route to explicit expander families, avoiding the heavy algebraic machinery (Margulis/LPS) that would require years of formalization effort.

Most theorems have `sorry` placeholders ‚Äî this is intentional. The codebase is a structural skeleton demonstrating the complete proof architecture.

## Build Commands

```bash
scripts/lean-check AKS/RegularGraph.lean    # Check a file (~0.2-2s for edits near end)
scripts/lean-check --all                    # Check all project files (use before committing)
scripts/lean-check --stop                   # Stop daemon (when done)
scripts/sorries                             # Audit sorry, #exit, native_decide, axiom across codebase
```

**Always use `lean-check` for verifying changes.** It keeps Mathlib imports in memory and re-elaborates only from the change point forward. Since proof iteration typically happens at the end of a file, most checks are sub-second. The daemon auto-starts on first use (~5s).

**Before committing, run `scripts/lean-check --all`** to verify all project files type-check. This catches cross-file breakage (e.g., a changed signature in one file breaking a downstream import) that single-file checks miss.

There are no tests or linter configurations. Correctness is verified through Lean's type checker ‚Äî if `lean-check` reports no errors, all type-checked proofs are valid.

### `lake build` (fallback only)

Use `lake build` only when debugging the `lean-check` daemon (e.g., if you suspect stale state). For checking all files, prefer `scripts/lean-check --all` ‚Äî it uses the daemon cache and is much faster.

```bash
lake build          # Full rebuild ‚Äî slow, use only as fallback
lake clean          # Clean build artifacts
```

### Python Scripts

Use `uv run` (not `pip install`) for Python scripts with dependencies:
```bash
uv run --with numpy --with networkx scripts/some_script.py
```

### Mathlib Searches

`rg` (ripgrep) through `.lake/packages/mathlib/Mathlib/` takes ~0.2s for any pattern. This is already fast. Example:
```bash
rg 'IsSelfAdjoint.norm_mul_self' .lake/packages/mathlib/Mathlib/
```

### Tool Speed Expectations

Track tool performance against these baselines. If a command exceeds its expected time by 2x+, investigate and record in `scripts/SLOW_COMMANDS.md`.

| Operation | Expected time | If slower, check |
|---|---|---|
| `rg` through Mathlib | ~0.2s | Disk I/O, cold cache |
| `lean-check` (warm, edit near end) | 0.2-2s | Daemon crashed? Restart |
| `lean-check` (cold, first open) | 20-30s | Normal for large files |
| `lake build` (all cached) | ~1.6s | Nothing changed? |
| `lake build` (one file changed) | ~20s | Normal; use `lean-check` instead |
| `git` operations | <1s | Large repo / network |

**Timeout protocol:** When any tool call times out, record it in `scripts/SLOW_COMMANDS.md` with context (what file, what operation, wall time). Then investigate root cause.

### Git

Use merge, not rebase: `git pull --no-rebase`. Never use `git pull --rebase`.

## Architecture

**Entry point:** `AKS.lean` ‚Äî imports all modules and states the top-level theorem `zigzag_implies_aks_network` connecting expander existence to sorting networks.

**Modules with bottom-up dependency:**

### `AKS/Fin.lean` ‚Äî `Fin` Arithmetic Helpers
Reusable encode/decode lemmas for `Fin n √ó Fin d` ‚Üî `Fin (n * d)` product indexing: `Fin.pair_lt`, `fin_encode_fst`, `fin_encode_snd`, `fin_div_add_mod`.

### `AKS/Basic.lean` ‚Äî Sorting Network Theory
Sections build on each other sequentially:
1. **Comparator networks** ‚Äî `Comparator`, `ComparatorNetwork` (flat list of comparators), execution model
2. **0-1 principle** ‚Äî reduces sorting correctness to Boolean inputs
3. **Expander graphs** ‚Äî `BipartiteExpander`, spectral gap, existence
4. **AKS construction** ‚Äî recursive build: split ‚Üí recurse ‚Üí merge with halvers
5. **Complexity analysis** ‚Äî `IsBigO` notation, O(n log n) size
6. **Correctness** ‚Äî `AKS.sorts`

### `AKS/Halver.lean` ‚Äî Œµ-Halver Theory
Œµ-halvers and their composition properties, the engine driving AKS correctness:
1. **Œµ-halvers** ‚Äî `IsEpsilonHalver`, `expander_gives_halver`, `epsHalverMerge`
2. **Halver composition** ‚Äî `IsEpsilonSorted`, `halver_composition` (geometric decrease), `halver_convergence`

### `AKS/RegularGraph.lean` ‚Äî Core Regular Graph Theory (~335 lines)
Core definitions and spectral gap, independent of specific constructions:
1. **Regular graphs and adjacency matrices** ‚Äî `RegularGraph` (rotation map representation), `adjMatrix`, symmetry proofs
2. **Walk and mean operators** ‚Äî `walkCLM` (CLM-first), `meanCLM`, `walkFun`/`walkLM`/`meanFun`/`meanLM` (three-layer pattern)
3. **Spectral gap** ‚Äî `spectralGap` := `‚ÄñwalkCLM - meanCLM‚Äñ` (operator norm), `spectralGap_nonneg`, `spectralGap_le_one`

### `AKS/Square.lean` ‚Äî Graph Squaring (~225 lines)
Graph squaring and the spectral gap squaring identity:
1. **Graph squaring** ‚Äî `G.square`, `adjMatrix_square_eq_sq`
2. **CLM identities** ‚Äî self-adjointness, idempotency, `WP = PW = P`
3. **Spectral gap squaring** ‚Äî `spectralGap_square`: Œª(G¬≤) = Œª(G)¬≤

### `AKS/CompleteGraph.lean` ‚Äî Complete Graph (~108 lines)
The complete graph as a concrete example:
1. **Complete graph** ‚Äî `completeGraph` via `Fin.succAbove`/`Fin.predAbove`
2. **Spectral gap** ‚Äî `spectralGap_complete`: Œª(K_{n+1}) = 1/n

### `AKS/Mixing.lean` ‚Äî Expander Mixing Lemma
Fully proved expander mixing lemma via indicator vectors + Cauchy-Schwarz + operator norm.

### `AKS/Random.lean` ‚Äî Base Expander for Zig-Zag Construction
Axiomatized base expander (chosen by fair dice roll, guaranteed to be random):
1. **`baseExpander`** ‚Äî axiom: 12-regular graph on 20736 = 12‚Å¥ vertices
2. **`baseExpander_gap`** ‚Äî axiom: spectral gap ‚â§ 5/9 ‚âà 0.556 (just above Alon‚ÄìBoppana 2‚àö11/12 ‚âà 0.553)
3. **Certificate analysis** ‚Äî all O(n)-data approaches (SDD, edge PSD, Krylov) are infeasible; see file header

### `AKS/ZigZagOperators.lean` ‚Äî Zig-Zag Product and Walk Operators (~230 lines)
Defines the zig-zag product and the three CLM operators for its spectral analysis:
1. **Zig-zag product** ‚Äî `G‚ÇÅ.zigzag G‚ÇÇ`, the three-step walk (zig-step-zag)
2. **Cluster encoding** ‚Äî `cluster`/`port`/`encode` helpers for `Fin (n‚ÇÅ * d‚ÇÅ)` ‚Üî `Fin n‚ÇÅ √ó Fin d‚ÇÅ`
3. **Within-cluster walk** ‚Äî `withinClusterCLM` (`B = I ‚äó W_{G‚ÇÇ}`)
4. **Step permutation** ‚Äî `stepPermCLM` (`Œ£`: permutes via `G‚ÇÅ.rot`)
5. **Cluster mean** ‚Äî `clusterMeanCLM` (`Q`: averages within each cluster)
6. **Walk factorization** ‚Äî `zigzag_walkCLM_eq`: `W_Z = B ¬∑ Œ£ ¬∑ B`

### `AKS/ZigZagSpectral.lean` ‚Äî Zig-Zag Operator Properties (~130 lines)
Algebraic identities and spectral bounds for the zig-zag operators:
1. **Algebraic properties** ‚Äî `Q¬≤ = Q`, `Q* = Q`, `B* = B`, `Œ£¬≤ = 1`, `Œ£* = Œ£`, `BQ = QB = Q`
2. **Tilde contraction** ‚Äî `‚ÄñB(I-Q)‚Äñ ‚â§ spectralGap G‚ÇÇ`
3. **Hat block norm** ‚Äî `‚ÄñQŒ£Q - P‚Äñ ‚â§ spectralGap G‚ÇÅ`
4. **Global mean decomposition** ‚Äî `P¬∑Q = Q¬∑P = P`

### `AKS/RVWBound.lean` ‚Äî Abstract RVW Operator Bound (~85 lines)
Pure operator theory, no graph imports:
1. **`rvwBound`** ‚Äî the precise RVW bound function
2. **Monotonicity** ‚Äî `rvwBound_mono_left`, `rvwBound_mono_right`
3. **Abstract bound** ‚Äî `rvw_operator_norm_bound`: `‚ÄñW - P‚Äñ ‚â§ rvwBound(Œª‚ÇÅ, Œª‚ÇÇ)` from operator axioms

### `AKS/ZigZag.lean` ‚Äî Expander Families (~115 lines)
Assembles the spectral bound and builds the iterated construction:
1. **Spectral composition theorem** ‚Äî `zigzag_spectral_bound` (assembles sublemmas)
2. **Iterated construction** ‚Äî `zigzagFamily`: square ‚Üí zig-zag ‚Üí repeat
3. **Main result** ‚Äî `explicit_expanders_exist_zigzag`

### Data flow
```
Fin.lean ‚Üí RegularGraph.lean ‚Üí Square.lean ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ZigZag.lean
                              ‚Üí CompleteGraph.lean              ‚Üì
                              ‚Üí Mixing.lean               AKS.lean
                              ‚Üí ZigZagOperators.lean ‚îÄ‚îÄ‚Üí      ‚Üë
                                  ZigZagSpectral.lean ‚îÄ‚Üó  Basic.lean ‚Üí Halver.lean
           Random.lean ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üó
           RVWBound.lean ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üó
```

## Style

- Use `‚Ü¶` (not `=>`) for lambda arrows: `fun x ‚Ü¶ ...`
- In markdown/comments, backtick-quote Lean identifiers and filenames: `` `Fin` ``, not `Fin`; `` `ZigZag.lean` ``, not `ZigZag.lean`
- Use `/-! **Title** -/` for section headers, not numbered `¬ßN.` or decorative `-- ‚ïê‚ïê‚ïê` lines
- Keep mathematically high-level files (e.g., `ZigZag.lean`) clean by moving reusable helpers (e.g., `Fin` arithmetic lemmas) into their own files (e.g., `AKS/Fin.lean`). Iterate with helpers in the same file during development, then extract as a final pass before committing.
- Split files that grow beyond ~300 lines. Smaller files mean faster incremental checking (the Lean server re-elaborates from the change point, but only within the current file ‚Äî imports are precompiled). The optimal split point for tooling-assisted development is smaller than for human-authored files.
- Prefer algebraic notation over explicit constructor names when a typeclass instance exists: `1` not `ContinuousLinearMap.id ‚Ñù _`, `a * b` not `ContinuousLinearMap.comp a b`, `0` not `ContinuousLinearMap.zero`, etc. The algebraic forms are shorter, more readable, and match how mathematicians write. Don't add type ascriptions ‚Äî if the other operand pins the type (e.g., `1 - meanCLM n`), bare `1` suffices.
- **Parameterize theorems over abstract bounds, not hard-coded constants.** Theorem statements should take spectral gap bounds (Œ≤, c, etc.) as parameters with hypotheses encoding the required inequalities, rather than baking in specific fractions like `1/5` or `1/2`. Proofs should chain `.trans` through these hypotheses, not `norm_num` specific arithmetic. Similarly, prefer explicit types/degrees (e.g., `D * D`) over existential quantification (`‚àÉ d`), and take concrete objects (like base expanders) as parameters rather than using axioms directly in theorem statements. The motivation: we eventually want explicit sorting network code with explicit constants (even if those constants are galactic), which requires every bound to be computable and extractable ‚Äî not hidden inside an existential or baked into a proof term.

## Key Lean/Mathlib Conventions

- `autoImplicit` is **disabled** globally in `lakefile.lean` ‚Äî do not add `set_option autoImplicit false` in individual files
- Depends on **Mathlib v4.27.0** ‚Äî when updating, check import paths as they frequently change between versions (this has caused build breaks before)
- Lean toolchain: **v4.27.0** (pinned in `lean-toolchain`)
- **Avoid `native_decide`** ‚Äî it compiles to native code, which sidesteps the kernel's trust boundary. Prefer `decide +kernel` (a faster variant of `decide` that uses the kernel evaluator) when `decide` alone is too slow. Only use `native_decide` as a last resort for computations that are truly infeasible in the kernel.

## Proof Workflow

Before attempting a `sorry`, estimate the probability of proving it directly (e.g., 30%, 50%, 80%) and report this. If the probability is below ~50%, first factor the `sorry` into intermediate lemmas ‚Äî smaller steps that are each individually likely to succeed. This avoids wasting long build-test cycles on proofs that need restructuring.

**Recognize thrashing and ask the user.** If you attempt 3+ substantially different approaches to the same goal without progress (especially if you catch yourself thinking "I'm overcomplicating this"), stop and ask the user for guidance. They may see a cleaner mathematical reformulation or an alternative approach to the theory. A 2-minute conversation is cheaper than 30 minutes of failed build cycles. Signs of thrashing: repeated restructuring of the same proof, oscillating between approaches, or growing helper lemma counts without the main goal getting closer.

**Keep proofs small and factored.** If a proof has more than ~3 intermediate `have` steps that later steps depend on, factor the intermediates into standalone lemmas. Long proofs with deep dependency chains cause churning: fixing one step breaks steps below it, and each build-test cycle is expensive. Each lemma should have a small, independently testable interface. Concretely: if you're building `C` from `B` from `A` all inside one proof, extract `A` and `B` as lemmas so you can iterate on each in isolation.

**Prefer point-free (abstract) formulations over coordinate-based ones.** Proofs about linear algebra, spectral theory, or similar can be dramatically cleaner when stated in terms of operator identities (e.g., `(M-P)¬≤ = M¬≤-P` from `MP = P`) rather than entry-wise coordinate calculations (e.g., sorted eigenvalue multiset matching). Before diving into a coordinate proof, ask whether there's an abstract reformulation ‚Äî a projection, an operator norm, a functional calculus ‚Äî that makes the key identity fall out algebraically. The payoff compounds: abstract identities compose cleanly, while coordinate proofs each require their own index bookkeeping. **Exception:** when there's a single canonical basis and the proof is naturally a finite computation (e.g., `adjMatrix_row_sum`), coordinates are fine.

**When a user suggests an approach or lesson, rephrase it for CLAUDE.md** rather than copying verbatim. Lessons should be concise, actionable, and fit the existing style. This also applies to self-generated lessons: distill the insight before recording it.

## Proof Tactics

After completing each proof, reflect on what worked and what didn't. If there's a reusable lesson ‚Äî a tactic pattern, a Mathlib gotcha, a refactoring that unlocked progress ‚Äî add it here (not in auto memory). This file is the single source of truth for accumulated lessons, so they persist across machines.

**Extract defs from `where` blocks before proving properties.** Proving involutions/identities inline in a `where` block produces goals with fully-unfolded terms ‚Äî nested `G.1` instead of `G.rot`, `Fin` literals with opaque `isLt` proof terms, and destructuring `let` compiled to `match`. Instead: extract the function as a standalone `private def` using `.1`/`.2` projections (not `let ‚ü®a, b‚ü© := ...`), prove properties as separate theorems, plug both into the `where` block. Then `simp only [my_def, ...]` can unfold + rewrite in one pass. See `square_rot` / `square_rot_involution` in `RegularGraph.lean`.

**Generalize helper lemmas from the start.** Write `Fin` arithmetic helpers with the most general signature that makes sense (e.g., `Fin n √ó Fin d`, not `Fin d √ó Fin d`). The `square` helpers were initially specialized and had to be re-generalized for `zigzag`. General versions cost nothing extra and prevent rework.

**`Fin` simp lemmas: quantify over proof terms.** When writing simp lemmas for `Fin` encode/decode, take the `isLt` proof as a parameter `(h : ... < d)` so the lemma matches any proof term Lean generates internally.

**`Fin` arithmetic: `omega` vs. specialized lemmas.** `omega` handles linear `Nat` arithmetic but not nonlinear (`a * b` where both vary). For `j * d + i < n * d`: use `calc` with `Nat.add_lt_add_left` + `Nat.mul_le_mul_right`. For div/mod: `Nat.add_mul_div_right`, `Nat.add_mul_mod_self_right`, `Nat.div_eq_of_lt`, `Nat.mod_eq_of_lt`. For `(ij/d)*d + ij%d = ij`: `rw [Nat.mul_comm]; exact Nat.div_add_mod` (`omega` can't prove this).

**Search Mathlib before writing custom helpers.** Before defining a helper function or writing a manual proof, check whether Mathlib already provides it ‚Äî existing helpers come with simp lemmas, API, and composability that custom code won't have. This applies especially to `Fin` operations, order theory, and algebraic identities. Examples found so far: `Fin.succAbove`/`Fin.predAbove` (skip-one-value embeddings with involution lemmas), `Monotone.map_min`/`Monotone.map_max` (`Mathlib.Order.MinMax`). To search: grep `.lake/packages/mathlib` for keywords (fastest), or use `#check @Fin.someName` in a scratch file to test if a name exists. Reparameterize types to match Mathlib conventions (e.g., `Fin (n+1)` instead of `Fin d` with `hd : d ‚â• 2`).

**Avoid inline `‚ü®expr, by omega‚ü©` inside definitions.** Constructing `Fin` values with embedded proof terms inside a `def` creates opaque terms that `omega`/`simp` can't see through after unfolding (`omega` cannot reduce `(‚ü®a, h‚ü© : Fin n).val` or `(x, y).1` after `split_ifs`). Instead use Mathlib helpers (see above) or named functions with `.val` simp lemmas. This turned `complete_rot_involution` from 8+ failed attempts into a 2-line `simp only` proof.

**Prefer `apply` over `exact` when arguments are inferrable.** `exact G.foo v i` can be shortened to `apply G.foo` when `v` and `i` are determined by unification with the goal. This is common after `rw` rewrites that leave a goal matching the lemma's conclusion.

**When stuck after 2-3 attempts, step back and refactor** rather than trying more tactic variations on the same structure. Repeated `omega`/`simp` failures usually indicate the definitions need restructuring, not a cleverer tactic combination.

**Define CLMs in three layers: standalone function ‚Üí LinearMap ‚Üí CLM.** (1) Define the function on plain vectors (`Fin n ‚Üí ‚Ñù`) as a standalone `def`, so proofs can `simp`/`unfold` it without fighting type wrappers. (2) Wrap it as a `‚Üí‚Çó[‚Ñù]` on `EuclideanSpace`, using `WithLp.toLp 2` / `WithLp.ofLp` to bridge: `toFun f := WithLp.toLp 2 (myFun (WithLp.ofLp f))`. Prove `map_add'` and `map_smul'` via `apply PiLp.ext; intro v; simp [myFun, ...]`. (3) Promote to `‚ÜíL[‚Ñù]` via `LinearMap.toContinuousLinearMap` (free in finite dimension). Finally, prove an `@[simp]` lemma `myCLM_apply` unpacking the CLM to the standalone function ‚Äî this is typically `rfl` because `ofLp_toLp` is `rfl`. See `walkFun` / `walkLM` / `walkCLM` / `walkCLM_apply` in `RegularGraph.lean`.

**Triangle inequality for `|¬∑|` via `dist_triangle`.** `abs_add` is hard to find. Instead, convert to the metric space API: `|Œº| = ‚ÄñŒº‚Äñ = dist Œº 0` (via `Real.norm_eq_abs`, `dist_zero_right` ‚Äî no `Real.` prefix), then `dist_triangle Œº c 0` gives `|Œº| ‚â§ dist Œº c + ‚Äñc‚Äñ`. Use `Real.dist_eq` for `dist x y = |x - y|`.

**`‚Üë(Finset.univ)` ‚â† `Set.univ` in `MapsTo` proofs.** `card_eq_sum_card_fiberwise` needs `(s : Set Œπ).MapsTo f ‚Üët`. The coercion `‚Üë(Finset.univ)` is `Finset.univ.toSet`, not `Set.univ`. Use `Finset.mem_coe.mpr (Finset.mem_univ _)` to prove `x ‚àà ‚Üëuniv`.

**Matrix product entries via fiber decomposition.** To prove `adjMatrix G.square = (adjMatrix G) ^ 2`, reduce entry-wise to a Nat equality: `#{two-step walks u‚Üív} = ‚àë_w #{edges u‚Üíw} √ó #{edges w‚Üív}`. Use `Finset.card_eq_sum_card_fiberwise` to partition the LHS by intermediate vertex, then `Finset.card_nbij'` with div/mod encoding to biject each fiber with a product of filters. The `fin_encode_fst`/`fin_encode_snd`/`fin_div_add_mod` lemmas from `Fin.lean` handle the round-trip proofs. For the ‚Ñù-level: `simp only [adjMatrix_apply, sq, Matrix.mul_apply, div_mul_div_comm]` + `rw [‚Üê Finset.sum_div, Nat.cast_mul]` + `congr 1` reduces to the Nat identity, then `exact_mod_cast key`.

**Connecting `eigenvalues‚ÇÄ` to `spectrum`.** To show `hA.eigenvalues‚ÇÄ j ‚àà spectrum ‚Ñù A`: (1) `rw [hA.spectrum_real_eq_range_eigenvalues]`, (2) construct witness `‚ü®(Fintype.equivOfCardEq (Fintype.card_fin _)) j, proof‚ü©`, (3) prove equality with `unfold Matrix.IsHermitian.eigenvalues; simp [Equiv.symm_apply_apply]`. Key insight: `eigenvalues i = eigenvalues‚ÇÄ (equiv.symm i)`, so `eigenvalues (equiv j) = eigenvalues‚ÇÄ j`.

**Bridging `eigenvalues‚ÇÄ` ‚Üî `eigenvalues` dichotomies.** To lift a result about `eigenvalues j` (indexed by `Fin (n+1)`) to `eigenvalues‚ÇÄ k` (indexed by `Fin (Fintype.card (Fin (n+1)))`): prove `eigenvalues‚ÇÄ k ‚àà Set.range eigenvalues` via the `spectrum` recipe above, then `obtain ‚ü®j, hj‚ü©` and substitute. Avoids constructing `Fintype.equivOfCardEq` explicitly. For sums: `change ‚àë j, eigenvalues‚ÇÄ (equiv.symm j) = _; exact Equiv.sum_comp _ _`.

**`set` + external lemmas: use `rw [hA_def]`.** After `set hA := adjMatrix_isHermitian G with hA_def`, the goal uses `hA` but external lemmas produce `(adjMatrix_isHermitian G).eigenvalues‚ÇÄ`. Use `rw [hA_def]` to convert back before `exact`. Define derived hypotheses (dichotomy, sum) inside the proof with `intro k; rw [hA_def]; exact external_lemma k` so they match the `set` binding.

**Star instance diamond on CLMs.** `IsSelfAdjoint` for CLMs uses `ContinuousLinearMap.instStarId`, but `IsSelfAdjoint.sub` and `IsSelfAdjoint.norm_mul_self` expect `StarAddMonoid.toInvolutiveStar.toStar` (from `[StarRing E]`). These are propositionally but not definitionally equal. **Workaround for `.sub`:** go through `LinearMap.IsSymmetric.sub` ‚Äî convert to `IsSymmetric` via `isSelfAdjoint_iff_isSymmetric`, use `ContinuousLinearMap.coe_sub` to decompose the coercion, apply `IsSymmetric.sub`. **Workaround for `.norm_mul_self`:** use `rw [‚Üê hsa.norm_mul_self]` (rewrite) instead of `exact hsa.norm_mul_self.symm` ‚Äî `rw` is more lenient about instance matching than `exact`. More broadly, when typeclass diamonds cause `exact` to fail, try `rw` ‚Äî it performs less strict instance checking.

**`Finset.sum_comm` loops in `simp_rw`.** `simp_rw` applies under binders, so `simp_rw [Finset.sum_comm]` endlessly rewrites nested sums. Use `conv_rhs => rw [Finset.sum_comm]` (or `conv_lhs`) to apply it exactly once at the desired position.

**CLM self-adjointness via inner products.** To prove `IsSelfAdjoint A` for a CLM on `EuclideanSpace ‚Ñù (Fin n)`: (1) `rw [ContinuousLinearMap.isSelfAdjoint_iff_isSymmetric]; intro f g; change @inner ‚Ñù _ _ (A f) g = @inner ‚Ñù _ _ f (A g)` (2) decompose with `simp only [PiLp.inner_apply, RCLike.inner_apply, conj_trivial, myCLM_apply]` (3) rearrange sums. Handle d=0 separately. For `IsSelfAdjoint (A - B)` from `IsSelfAdjoint A` and `IsSelfAdjoint B`: use the Star diamond workaround above (`IsSymmetric.sub`).

**`ext f v` on `EuclideanSpace` CLM equalities produces `.ofLp` goals.** After `ext f v` on `A f = B f` where the codomain is `EuclideanSpace ‚Ñù (Fin n)`, the second `ext v` produces goals with `(... f).ofLp v` wrapping. Simp lemmas like `meanCLM_apply` and `walkCLM_apply` (which match `f v` form) may not fire. **Fix:** use `refine ContinuousLinearMap.ext (fun f ‚Ü¶ ?_); apply PiLp.ext; intro v; show A f v = B f v` ‚Äî the `show` converts from `ofLp` to plain function application (definitionally equal). Then `rw`/`simp` with `_apply` lemmas works.

**`Fin n` has no `OfNat 0` or `OfNat 1` when `n` is variable.** Use `‚ü®0, by omega‚ü© : Fin n` (with proof that `n > 0`) instead of `(0 : Fin n)`. Same for `1`. Bind with `set v0 : Fin n := ‚ü®0, by omega‚ü©` for reuse.

**`field_simp` leaves `‚Üë(1 + n)` and `‚Üën` as separate atoms.** `ring` can't close the goal because it treats them as independent variables. Fix: add `push_cast` between `field_simp` and `ring` to normalize `‚Üë(1 + n)` to `1 + ‚Üën`.

**`split_ifs` on nested ifs creates impossible branch combinations.** `if a then 1 else if b then -1 else 0` with `split_ifs` creates a case `a ‚àß b` even when `a` and `b` are mutually exclusive. Handle with `exact absurd (h1.symm.trans h2) hne`. Alternatively, decompose nested ifs into sums of single ifs (`= (if a then 1 else 0) + (if b then -1 else 0)`) via a helper lemma, then use `Finset.sum_add_distrib` + `Finset.sum_ite_eq'`.

**`Equiv.sum_comp` for rotation-bijection sum swaps.** To show `‚àë v ‚àë i, f(nbr v i) ¬∑ g v = ‚àë v ‚àë i, f v ¬∑ g(nbr v i)`: reindex via `G.rotEquiv.sum_comp (fun q ‚Ü¶ f q.1 * g (G.rot q).1)`, then `simp only [show ‚àÄ p, (G.rotEquiv p : _) = G.rot p from fun _ ‚Ü¶ rfl, G.rot_involution]`. The `show` lemma bridges the `Equiv` coercion with the raw `rot` function. Don't use `Equiv.sum_comp` inside `calc` ‚Äî it fails to unify when the coercion differs.

**`linarith` can't handle division.** `1/‚Üën > 0` doesn't follow from `‚Üën > 0` in `linarith`'s linear fragment. Provide it as `have : (0:‚Ñù) < 1 / ‚Üën := by positivity`. Similarly, `(‚Üën + 1)/‚Üën = 1 + 1/‚Üën` needs `field_simp` to make `linarith`-accessible.

**`spectralGap_le_one` proof pattern: contraction + WP = P.** To show `‚ÄñW - P‚Äñ ‚â§ 1` for walk operator W and mean projection P: (1) prove `‚ÄñW‚Äñ ‚â§ 1` via `opNorm_le_bound` + Cauchy-Schwarz (`sq_sum_le_card_mul_sum_sq` from `Mathlib.Algebra.Order.Chebyshev`) + double-counting via `rotEquiv.sum_comp`; (2) prove `WP = P` (walk of a constant = same constant); (3) prove `‚Äñf - Pf‚Äñ ‚â§ ‚Äñf‚Äñ` via `field_simp` + `nlinarith`; (4) factor `(W-P)f = W(f - Pf)` and chain inequalities. Handle d = 0 separately with `‚ÄñPf‚Äñ ‚â§ ‚Äñf‚Äñ` (Cauchy-Schwarz). Key Lean pitfall: `Nat.cast_ne_zero.mpr` often has type-class mismatch issues; use `by positivity` instead.

**Indicator vector pattern for combinatorial-spectral bridges.** To relate a combinatorial quantity (edge count between sets) to a spectral bound (operator norm): (1) define `indicatorVec S` via `(WithLp.equiv 2 _).symm (fun v ‚Ü¶ if v ‚àà S then 1 else 0)` with an `@[simp]` apply lemma that's `rfl`; (2) prove `‚ÄñindicatorVec S‚Äñ = ‚àö‚ÜëS.card` via `EuclideanSpace.norm_sq_eq` + `sum_boole`; (3) express the combinatorial quantity as `‚ü®1_S, A(1_T)‚ü©` by unfolding inner product (`PiLp.inner_apply` + `RCLike.inner_apply` + `conj_trivial`), then using `ite_mul`/`sum_filter`/`sum_boole` to convert indicator sums to filter cardinalities; (4) apply `abs_real_inner_le_norm` (Cauchy-Schwarz) + `le_opNorm` for the spectral bound. Key tactic sequence for indicator sums: `simp_rw [ite_mul, one_mul, zero_mul]; rw [‚Üê Finset.sum_filter]; have : univ.filter (¬∑ ‚àà S) = S := by ext; simp`.

## Mathlib API Reference

### Spectral Theorem
- Import: `Mathlib.Analysis.Matrix.Spectrum` (transitively imports eigenspace)
- `IsHermitian.eigenvalues‚ÇÄ : Fin (Fintype.card n) ‚Üí ‚Ñù` ‚Äî eigenvalues in decreasing order
- `eigenvalues‚ÇÄ_antitone : Antitone hA.eigenvalues‚ÇÄ`
- For real matrices: `conjTranspose_eq_transpose_of_trivial` converts `IsHermitian` ‚Üî `IsSymm`
- `Fintype.card (Fin n)` is NOT definitionally `n`; use `rw [Fintype.card_fin]; omega` for index proofs

### Gershgorin Circle Theorem
- Import: `Mathlib.LinearAlgebra.Matrix.Gershgorin`
- `eigenvalue_mem_ball`: needs `HasEigenvalue (toLin' A) Œº`; gives `‚àÉ k, Œº ‚àà closedBall (A k k) (‚àë j ‚àà univ.erase k, ‚ÄñA k j‚Äñ)`
- Chain: `spectrum_toLin'` (bridge matrix ‚Üî linear map spectra) ‚Üí `HasEigenvalue.of_mem_spectrum` ‚Üí `eigenvalue_mem_ball`

### Fin Sums
- `Fin.sum_univ_succAbove (f : Fin (n+1) ‚Üí M) (x : Fin (n+1)) : ‚àë i, f i = f x + ‚àë i, f (x.succAbove i)` ‚Äî decompose sum by separating one index; import `Mathlib.Algebra.BigOperators.Fin`

### Finset Counting
- `Finset.card_nbij'` takes `Set.MapsTo`/`Set.LeftInvOn`/`Set.RightInvOn` args
- `card_eq_sum_card_fiberwise` needs `Set.MapsTo` proof (see `‚Üëuniv` note above)
- `Finset.sum_ite_eq' (s : Finset Œ±) (a : Œ±) (b : Œ± ‚Üí Œ≤) : ‚àë x ‚àà s, (if x = a then b x else 0) = if a ‚àà s then b a else 0`

### ContinuousLinearMap / C*-Algebra (spectral gap infrastructure)
- Import: `Mathlib.Analysis.CStarAlgebra.Matrix` (provides `Matrix.toEuclideanCLM`)
- `Matrix.toEuclideanCLM (ùïú := ‚Ñù) (n := Fin n) : Matrix (Fin n) (Fin n) ‚Ñù ‚âÉ‚ãÜ‚Çê[‚Ñù] (EuclideanSpace ‚Ñù (Fin n) ‚ÜíL[‚Ñù] EuclideanSpace ‚Ñù (Fin n))` ‚Äî star algebra equivalence
- As a `StarAlgEquiv`, it preserves `star`, `*`, `+`, `1`, and scalar multiplication: use `map_sub`, `map_smul`, `map_one`, `map_mul`, etc.
- `star` on CLMs is the Hilbert adjoint; `star` on `Matrix n n ‚Ñù` is `conjTranspose = transpose` (for reals)
- `CStarRing (E ‚ÜíL[ùïú] E)` instance exists (from `Mathlib.Analysis.InnerProductSpace.Adjoint`): gives `CStarRing.norm_star_mul_self : ‚Äñx‚ãÜ * x‚Äñ = ‚Äñx‚Äñ * ‚Äñx‚Äñ`
- `IsSelfAdjoint.norm_mul_self : ‚Äñx * x‚Äñ = ‚Äñx‚Äñ ^ 2` ‚Äî for self-adjoint elements in a C*-ring
- Combined with idempotency (`p * p = p`): `‚Äñp‚Äñ = ‚Äñp‚Äñ¬≤` ‚Üí `‚Äñp‚Äñ ‚àà {0, 1}`
- Explicit type params needed: `(Matrix.toEuclideanCLM (ùïú := ‚Ñù) (n := Fin n))` ‚Äî without them, coercion from `StarAlgEquiv` fails

## Architectural Direction: CLM-First Definitions

**Goal:** define graph operators natively as CLMs on `EuclideanSpace`, not as matrices. `walkCLM` and `meanCLM` are defined CLM-first (three-layer pattern: standalone function ‚Üí `LinearMap` ‚Üí CLM via `toContinuousLinearMap`). `spectralGap` is now `‚ÄñwalkCLM - meanCLM‚Äñ`, the operator norm of the walk operator restricted to the orthogonal complement of constants.

No files have `#exit`. `expander_mixing_lemma` is fully proved via indicator vectors + Cauchy-Schwarz + operator norm. `ZigZag.lean` has 2 sorry's: `zigzag_spectral_bound` (assembly) and `explicit_expanders_exist_zigzag` (all-sizes interpolation). The `zigzag_spectral_bound` sorry has been decomposed into 16 smaller sublemmas across three new files: `ZigZagOperators.lean` (1 sorry: walk factorization), `ZigZagSpectral.lean` (12 sorry's: algebraic + spectral properties), and `RVWBound.lean` (3 sorry's: monotonicity + abstract operator bound). The mathematical core is `rvw_operator_norm_bound` in `RVWBound.lean` ‚Äî a pure operator-theory result independent of graphs. Base expander is D=12 (20736 vertices, Œ≤ ‚â§ 5/9); D=12 is minimal for the precise RVW bound to converge (Œ≤¬≤ < 1/3 + even parity). The next frontier is proving the easier sublemmas (algebraic properties).

## Proof Status by Difficulty

**Done:** `zero_one_principle`, `RegularGraph.square`, `RegularGraph.zigzag`, `completeGraph.rot_involution`, `spectralGap_nonneg`, `spectralGap_le_one`, `adjMatrix_square_eq_sq`, `spectralGap_square`, `spectralGap_complete`, `zigzagFamily`, `zigzagFamily_gap` (both cases), `expander_mixing_lemma`

**Achievable (weeks):** `halver_convergence`

**Achievable (weeks each):** The 16 sublemmas of `zigzag_spectral_bound`, decomposed as follows:
- *Easy (days):* `clusterMeanCLM_idempotent`, `clusterMeanCLM_isSelfAdjoint`, `stepPermCLM_sq_eq_one`, `withinCluster_comp_clusterMean`, `clusterMean_comp_withinCluster`, `meanCLM_eq_clusterMean_comp`, `clusterMean_comp_meanCLM`, `rvwBound_mono_left`, `rvwBound_mono_right`
- *Medium (1-2 weeks):* `withinClusterCLM_isSelfAdjoint`, `stepPermCLM_isSelfAdjoint`, `withinClusterCLM_norm_le_one`, `zigzag_walkCLM_eq`, `hat_block_norm`, `withinCluster_tilde_contraction`, assembly of `zigzag_spectral_bound`
- *Hard (2-4 weeks):* `rvw_operator_norm_bound` (mathematical core ‚Äî Rayleigh quotient ‚Üí 2√ó2 matrix eigenvalue)

**Substantial (months):** `halver_composition`, `expander_gives_halver`

**Engineering (weeks, fiddly):** replacing `baseExpander` axiom with a concrete verified graph, all-sizes interpolation in `explicit_expanders_exist_zigzag`

### Base expander certificate: open approaches

Replacing the `baseExpander` axioms requires certifying that a specific 12-regular graph on 20736 vertices has spectral gap ‚â§ 5/9. All known O(n)-data approaches are infeasible (see `Random.lean` header). Two ideas under investigation:

1. **Parallel dense LDL^T via sharded subfiles.** The LDL^T certificate is O(n¬≤) data, but verification can be chopped into thousands of independent subfiles generated during the build and verified in parallel with `decide +kernel`. Each subfile checks a few rows of the factorization. Need to estimate: total data size, per-shard verification time, and whether Lean's build system can handle ~10K generated files.

2. **Eigenspace sparsity.** Random expanders might have high multiplicity in their second eigenvalue, allowing the eigenspace to be described with sparse data. If so, a certificate could consist of a few sparse eigenvectors + a spectral gap bound on the complement. Need numerical experiments on actual random 12-regular graphs to check eigenvalue multiplicities and eigenvector sparsity.
